{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/JSoyinka/anaconda2/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.cm as cmx\n",
    "import matplotlib.colors as colors\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression as LogReg\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer as Tfidf\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.tree import DecisionTreeClassifier as dt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_validation import KFold, cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import train_test_split as sk_split\n",
    "from sklearn.decomposition import TruncatedSVD as SVD\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "with open('reviews.json') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    "        \n",
    "for rev in data:\n",
    "    rev['cool'] = rev['votes']['cool']\n",
    "    rev['funny'] = rev['votes']['funny']\n",
    "    rev['useful'] = rev['votes']['useful']\n",
    "    del rev['votes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'duplicated'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-3d2f53f81a8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mduplicated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'business_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'text'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'date'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'user_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbefore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mreviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreviews\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreviews\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mduplicated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'business_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'text'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'date'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'user_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mafter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'duplicated'"
     ]
    }
   ],
   "source": [
    "reviews.duplicated(subset=['business_id', 'text', 'date', 'user_id'])\n",
    "before = reviews.shape[0]\n",
    "reviews = reviews.drop(reviews[reviews.duplicated(subset=['business_id', 'text', 'date', 'user_id'])].index)\n",
    "after = reviews.shape[0]\n",
    "\n",
    "print before - after, \"duplicates dropped\"\n",
    "\n",
    "reviews_2015 = reviews[(reviews['date'] >= '2015-01-01') & (reviews['date'] < '2016-01-01')]\n",
    "del reviews_2015['review_id']\n",
    "del reviews_2015['type']\n",
    "\n",
    "print reviews_2015.shape\n",
    "reviews_2015.to_json(\"json_2015.json\", orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vT12uXtdBQ10_lUcl-M40w</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>terrible experience....I am a local first of a...</td>\n",
       "      <td>0</td>\n",
       "      <td>C_xtIn19eKivN335dzjadg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aWMxTWSEqBvH2KhdGPLibQ</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Bad service at this location.\\n\\nGood iced cof...</td>\n",
       "      <td>0</td>\n",
       "      <td>T7J9ae0wTskrI_Bgwp-4cA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Z98h1BhssZeFfZvcVTYOpw</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>We have been to Maya's many times since it fir...</td>\n",
       "      <td>1</td>\n",
       "      <td>O7WaUuYwX45Ia6Mvf01UCw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3rwM9fPYPk9qDkEBOhyHbg</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>booked the hotel for new years, over the phone...</td>\n",
       "      <td>1</td>\n",
       "      <td>kq-4vbC1cHQbRKyDmwERSA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JpYn_HdxQNZQSlWWv4P6Iw</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Good, not great. Not a ton of tea options but ...</td>\n",
       "      <td>1</td>\n",
       "      <td>XweddetOpWNuJQ5mLb_5JQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id  cool       date  funny  stars  \\\n",
       "0  vT12uXtdBQ10_lUcl-M40w     0 2015-01-01      0      1   \n",
       "1  aWMxTWSEqBvH2KhdGPLibQ     0 2015-01-01      0      3   \n",
       "2  Z98h1BhssZeFfZvcVTYOpw     0 2015-01-01      0      2   \n",
       "3  3rwM9fPYPk9qDkEBOhyHbg     1 2015-01-01      0      5   \n",
       "4  JpYn_HdxQNZQSlWWv4P6Iw     0 2015-01-01      0      3   \n",
       "\n",
       "                                                text  useful  \\\n",
       "0  terrible experience....I am a local first of a...       0   \n",
       "1  Bad service at this location.\\n\\nGood iced cof...       0   \n",
       "2  We have been to Maya's many times since it fir...       1   \n",
       "3  booked the hotel for new years, over the phone...       1   \n",
       "4  Good, not great. Not a ton of tea options but ...       1   \n",
       "\n",
       "                  user_id  \n",
       "0  C_xtIn19eKivN335dzjadg  \n",
       "1  T7J9ae0wTskrI_Bgwp-4cA  \n",
       "2  O7WaUuYwX45Ia6Mvf01UCw  \n",
       "3  kq-4vbC1cHQbRKyDmwERSA  \n",
       "4  XweddetOpWNuJQ5mLb_5JQ  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_json('json_2015.json')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samp = data.sample(50000) #draw samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english', binary=False, max_features=10000) #using non-binary Count Vec.\n",
    "reviews = samp.text.values\n",
    "\n",
    "#tokenize words\n",
    "x = vectorizer.fit_transform(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "binary_y = [] #class observations according to whether they have at least one \"helpful\" vote\n",
    "\n",
    "for score in samp.useful.values:\n",
    "    i = 1 if score > 0 else 0\n",
    "    binary_y.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C= 0.0001 : 0.646140014067\n",
      "C= 0.001 : 0.662779856527\n",
      "C= 0.01 : 0.66393987653\n",
      "C= 0.1 : 0.653520002091\n",
      "C= 1 : 0.627160042005\n",
      "C= 10 : 0.606280070737\n",
      "C= 100 : 0.600379882726\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEdCAYAAAAikTHKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x3fb812550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cvals = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100]\n",
    "scores = []\n",
    "for c in cvals: #try cross validating the data with different regularization parameters\n",
    "    log_model = LogReg(C=c, penalty='l2') #initiate unregularized logistic regression model\n",
    "    score = cross_val_score(log_model, x, binary_y, n_jobs=-1).mean() #cross validate\n",
    "    scores.append(score)\n",
    "    print \"C=\",c ,\":\", score\n",
    "    \n",
    "    \n",
    "plt.plot(cvals, scores)\n",
    "plt.xscale('log')\n",
    "plt.title(\"Accuracy by Regularization Parameter value\")\n",
    "plt.xlabel(\"Parameter value\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validated Accuracy on Sample: 0.66393987653\n"
     ]
    }
   ],
   "source": [
    "log_model = LogReg(C=0.01, penalty='l2') #initialize logistic regression model\n",
    "print \"Cross Validated Accuracy on Sample:\", cross_val_score(log_model, x, binary_y, n_jobs=-1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO CLASS BALANCE CORRECTION\n",
      "[[28903  2247]\n",
      " [12761  6089]]\n",
      "\n",
      "False Positive Rate: 0.0721348314607\n",
      "False Negative Rate: 0.676976127321\n",
      "True Positive Rate: 0.730446257198\n",
      "True Negative Rate: 0.693716397849\n",
      "\n",
      "Accuracy on Positive Reviews: 0.323023872679\n",
      "Accuracy on Negative Reviews: 0.927865168539\n",
      "Overall F1 Score: 0.377639697816\n",
      "\n",
      "\n",
      "WITH CLASS BALANCE CORRECTION\n",
      "[[24119  7031]\n",
      " [ 8301 10549]]\n",
      "\n",
      "False Positive Rate: 0.225714285714\n",
      "False Negative Rate: 0.440371352785\n",
      "True Positive Rate: 0.600056882821\n",
      "True Negative Rate: 0.743954349167\n",
      "\n",
      "Accuracy on Positive Reviews: 0.559628647215\n",
      "Accuracy on Negative Reviews: 0.774285714286\n",
      "Overall F1 Score: 0.512523895903\n"
     ]
    }
   ],
   "source": [
    "log_model = LogReg(C=0.01, penalty='l2') #initialize logistic regression model\n",
    "log_model.fit(x, binary_y)\n",
    "y_pred = log_model.predict(x)\n",
    "binary_y = np.array(binary_y)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(binary_y, y_pred).ravel() #from sklearn docs\n",
    "\n",
    "print \"NO CLASS BALANCE CORRECTION\"\n",
    "print confusion_matrix(binary_y, y_pred)\n",
    "print\n",
    "print \"False Positive Rate:\", fp/float(fp+tn)\n",
    "print \"False Negative Rate:\", fn/float(fn+tp)\n",
    "print \"True Positive Rate:\", tp/float(tp+fp)\n",
    "print \"True Negative Rate:\", tn/float(tn+fn)\n",
    "print\n",
    "print \"Accuracy on Positive Reviews:\", np.mean(y_pred[binary_y == 1] == binary_y[binary_y == 1])\n",
    "print \"Accuracy on Negative Reviews:\", np.mean(y_pred[binary_y == 0] == binary_y[binary_y == 0])\n",
    "\n",
    "print \"Overall F1 Score:\", cross_val_score(log_model, x, binary_y, n_jobs=-1, scoring='f1').mean()\n",
    "\n",
    "#BALANCED CLASSES\n",
    "log_model = LogReg(C=0.01, penalty='l2', class_weight='balanced') #initialize logistic regression model\n",
    "log_model.fit(x, binary_y)\n",
    "y_pred = log_model.predict(x)\n",
    "binary_y = np.array(binary_y)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(binary_y, y_pred).ravel() #from sklearn docs\n",
    "\n",
    "print \"\\n\\nWITH CLASS BALANCE CORRECTION\"\n",
    "print confusion_matrix(binary_y, y_pred)\n",
    "print\n",
    "print \"False Positive Rate:\", fp/float(fp+tn)\n",
    "print \"False Negative Rate:\", fn/float(fn+tp)\n",
    "print \"True Positive Rate:\", tp/float(tp+fp)\n",
    "print \"True Negative Rate:\", tn/float(tn+fn)\n",
    "print\n",
    "print \"Accuracy on Positive Reviews:\", np.mean(y_pred[binary_y == 1] == binary_y[binary_y == 1])\n",
    "print \"Accuracy on Negative Reviews:\", np.mean(y_pred[binary_y == 0] == binary_y[binary_y == 0])\n",
    "\n",
    "print \"Overall F1 Score:\", cross_val_score(log_model, x, binary_y, n_jobs=-1, scoring='f1').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#same procedure on full dataset\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words='english', binary=False, max_features=10000) #using non-binary Count Vec.\n",
    "reviews = data.text.values\n",
    "x = vectorizer.fit_transform(reviews)\n",
    "\n",
    "binary_y = []\n",
    "\n",
    "for score in data.useful.values:\n",
    "    i = 1 if score > 0 else 0\n",
    "    binary_y.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.655814588905\n",
      "F1 Score: 0.525511083732\n",
      "\n",
      "\n",
      "WITH CLASS BALANCE CORRECTION\n",
      "[[314277 101194]\n",
      " [119596 131748]]\n",
      "\n",
      "False Positive Rate: 0.243564532783\n",
      "False Negative Rate: 0.475825959641\n",
      "True Positive Rate: 0.56558284895\n",
      "True Negative Rate: 0.724352517903\n",
      "\n",
      "Accuracy on Positive Reviews: 0.524174040359\n",
      "Accuracy on Negative Reviews: 0.756435467217\n",
      "Overall F1 Score: 0.525511083732\n"
     ]
    }
   ],
   "source": [
    "log_model = LogReg(C=0.01, penalty='l2', class_weight='balanced') #initialize logistic regression model\n",
    "print \"Accuracy:\", cross_val_score(log_model, x, binary_y, n_jobs=-1).mean()\n",
    "print \"F1 Score:\",cross_val_score(log_model, x, binary_y, scoring='f1', n_jobs=-1).mean()\n",
    "\n",
    "log_model.fit(x, binary_y)\n",
    "y_pred = log_model.predict(x)\n",
    "binary_y = np.array(binary_y)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(binary_y, y_pred).ravel() #from sklearn docs\n",
    "\n",
    "print \"\\n\\nWITH CLASS BALANCE CORRECTION\"\n",
    "print confusion_matrix(binary_y, y_pred)\n",
    "print\n",
    "print \"False Positive Rate:\", fp/float(fp+tn)\n",
    "print \"False Negative Rate:\", fn/float(fn+tp)\n",
    "print \"True Positive Rate:\", tp/float(tp+fp)\n",
    "print \"True Negative Rate:\", tn/float(tn+fn)\n",
    "print\n",
    "print \"Accuracy on Positive Reviews:\", np.mean(y_pred[binary_y == 1] == binary_y[binary_y == 1])\n",
    "print \"Accuracy on Negative Reviews:\", np.mean(y_pred[binary_y == 0] == binary_y[binary_y == 0])\n",
    "\n",
    "print \"Overall F1 Score:\", cross_val_score(log_model, x, binary_y, n_jobs=-1, scoring='f1').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, while our baseline model establishes some degree of separation between helpful and unhelpful reviews it seems to have a relatively low accuracy and F1 score even when tuned. This is likely due to a confounding element of our question: the reality that reviews can lack \"useful\" votes for multiple reasons. \n",
    "\n",
    "On one hand, a review can have no useful votes when it actually contains useless content. This is the sort of review we'd like to classify as 0 or useless. On the other hand, a great review can recieve no useful votes simply because it goes unnoticed by other Yelp users. This likely impedes our model's capacity to make solid predictions regarding a review's helpfulness. A \"denominator\" value such as the sort seen in the Amazon dataset we looked at previously would help alleviate this issue.\n",
    "\n",
    "Given this difficulty, it will make sense for us to fit some additional models to the data to see which works best. Playing with class weights would also make sense, as the model currently seems to be making a fair number of false negative errors (which are severely impacting its performance). We can also explore other proxies for review quality, such as ratios between the different review classifications (useful, cool, funny) for a different review. Our baseline modeling approach is also extensible to direct analysis of the lingustic characteristics correlating with these other classifications.\n",
    "\n",
    "This model represents a decent start to what will be a more involved and nuanced project. Our next steps will be to play around with other modeling techniques and adjust parameters and inputs/weighting to try to reduce our false postiive and negative rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_json('json_2015.json')\n",
    "data = data.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9981</th>\n",
       "      <td>8PJSfnXpHoENxD-rsGGXWA</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>I stayed here with a group of friends for the ...</td>\n",
       "      <td>3</td>\n",
       "      <td>CUeJQCLwMl3LocFKNUm2tQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168112</th>\n",
       "      <td>5mMk3Ted-EOyHvJ-j9BhiQ</td>\n",
       "      <td>6</td>\n",
       "      <td>2015-04-09</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>More like a 3.5 for our particular experiences...</td>\n",
       "      <td>7</td>\n",
       "      <td>9A2-wSoBUxlMd3LwmlGrrQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607345</th>\n",
       "      <td>iUPJmJvHy9fVfRxsuwwdLQ</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-11-26</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>What a wonderful experience! Came in a little ...</td>\n",
       "      <td>0</td>\n",
       "      <td>jF4EiSxj3uv1WKR5Lt5ieQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57328</th>\n",
       "      <td>hUDeQq7KZXx_w7aFxdO-aQ</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-02-05</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>I came here six months ago when I was visiting...</td>\n",
       "      <td>1</td>\n",
       "      <td>roEWEvo1EQId1JguoLWISg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570859</th>\n",
       "      <td>qh04JalvbBzHL8xodlmlfg</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-11-06</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>Best service ever!! Kasey is a rockstar! \\nNo ...</td>\n",
       "      <td>0</td>\n",
       "      <td>H7cL5HQKriVcWVV8bH5WJg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   business_id  cool       date  funny  stars  \\\n",
       "9981    8PJSfnXpHoENxD-rsGGXWA     1 2015-01-06      1      4   \n",
       "168112  5mMk3Ted-EOyHvJ-j9BhiQ     6 2015-04-09      5      3   \n",
       "607345  iUPJmJvHy9fVfRxsuwwdLQ     0 2015-11-26      0      5   \n",
       "57328   hUDeQq7KZXx_w7aFxdO-aQ     2 2015-02-05      0      5   \n",
       "570859  qh04JalvbBzHL8xodlmlfg     0 2015-11-06      0      5   \n",
       "\n",
       "                                                     text  useful  \\\n",
       "9981    I stayed here with a group of friends for the ...       3   \n",
       "168112  More like a 3.5 for our particular experiences...       7   \n",
       "607345  What a wonderful experience! Came in a little ...       0   \n",
       "57328   I came here six months ago when I was visiting...       1   \n",
       "570859  Best service ever!! Kasey is a rockstar! \\nNo ...       0   \n",
       "\n",
       "                       user_id  \n",
       "9981    CUeJQCLwMl3LocFKNUm2tQ  \n",
       "168112  9A2-wSoBUxlMd3LwmlGrrQ  \n",
       "607345  jF4EiSxj3uv1WKR5Lt5ieQ  \n",
       "57328   roEWEvo1EQId1JguoLWISg  \n",
       "570859  H7cL5HQKriVcWVV8bH5WJg  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#standardize predictor variables\n",
    "\n",
    "def scorer_pos(estimator, X, y): #custom scoring functions to get positive and negative accuracy\n",
    "    y_pred = estimator.predict(X)\n",
    "    return np.float(np.mean(y_pred[y == 1] == y[y == 1]))\n",
    "\n",
    "def scorer_neg(estimator, X, y):\n",
    "    estimator.fit(X, y)\n",
    "    y_pred = estimator.predict(X)\n",
    "    return np.float(np.mean(y_pred[y == 0] == y[y == 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_model(x, binary_y, model, title, coefs=False):\n",
    "    model.fit(x, binary_y)\n",
    "    y_pred = model.predict(x)\n",
    "    binary_y = np.array(binary_y)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(binary_y, y_pred).ravel() #from sklearn docs\n",
    "\n",
    "    print title\n",
    "    print confusion_matrix(binary_y, y_pred)\n",
    "\n",
    "    print \"False Positive Rate:\", fp/float(fp+tn)\n",
    "    print \"False Negative Rate:\", fn/float(fn+tp)\n",
    "    print \"True Positive Rate:\", tp/float(tp+fp)\n",
    "    print \"True Negative Rate:\", tn/float(tn+fn)\n",
    "    \n",
    "    print \"Positive Accuracy:\", cross_val_score(model, x, binary_y, n_jobs=-1, scoring=scorer_pos).mean()\n",
    "    print \"Negative Accuracy:\", cross_val_score(model, x, binary_y, n_jobs=-1, scoring=scorer_neg).mean()\n",
    "    print \"Cross Validated Accuracy on Sample:\", cross_val_score(model, x, binary_y, n_jobs=-1).mean()\n",
    "    print \"Cross Validated AUC on Sample:\", cross_val_score(model, x, binary_y, n_jobs=-1, scoring='roc_auc').mean()\n",
    "    print \"Train Set Accuracy on Sample:\", np.mean(y_pred == binary_y)\n",
    "    print\n",
    "    if coefs == True:\n",
    "        mydict = zip(model.coef_[0], vectorizer.get_feature_names())\n",
    "        words = sorted([(i[0], i[1].encode('utf-8')) for i in mydict], reverse=True, key=lambda x: x[0])\n",
    "        return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "def tokenize(text):\n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stems = stem_tokens(tokens, stemmer)\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samp = data.sample(100000) #draw samples\n",
    "\n",
    "#lengths = [len(i[1]['text']) for i in samp.iterrows()]\n",
    "\n",
    "samp.shape\n",
    "frac_useful = 1 - data['useful'].value_counts()[0] / float(data.shape[0])\n",
    "frac_funny = 1 - data['funny'].value_counts()[0] / float(data.shape[0])\n",
    "frac_cool = 1 - data['cool'].value_counts()[0] / float(data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english', \n",
    "                             binary=False, \n",
    "                             max_features=10000,\n",
    "                             analyzer='word',\n",
    "                             #tokenizer=tokenize,\n",
    "                             sublinear_tf=False\n",
    "                            ) #using non-binary Count Vec.\n",
    "reviews = samp.text.values\n",
    "\n",
    "#tokenize words\n",
    "x = vectorizer.fit_transform(reviews)\n",
    "\n",
    "y_useful = [] #class observations according to whether they have at least one \"helpful\" vote\n",
    "y_cool = []\n",
    "y_funny = []\n",
    "\n",
    "\n",
    "for score in samp.useful.values:\n",
    "    i = 1 if score > 0 else 0\n",
    "    y_useful.append(i)\n",
    "\n",
    "for score in samp.cool.values:\n",
    "    i = 1 if score > 0 else 0\n",
    "    y_cool.append(i)\n",
    "\n",
    "for score in samp.funny.values:\n",
    "    i = 1 if score > 0 else 0\n",
    "    y_funny.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Useful\n",
      "[[38657 23529]\n",
      " [13939 23875]]\n",
      "False Positive Rate: 0.378364905284\n",
      "False Negative Rate: 0.368620087798\n",
      "True Positive Rate: 0.503649481056\n",
      "True Negative Rate: 0.734979846376\n",
      "Positive Accuracy: 0.620696071543\n",
      "Negative Accuracy: 0.609043857753\n",
      "Cross Validated Accuracy on Sample: 0.610769927887\n",
      "Cross Validated AUC on Sample: 0.653549500243\n",
      "Train Set Accuracy on Sample: 0.62532\n",
      "\n",
      "Funny\n",
      "[[52392 30194]\n",
      " [ 5666 11748]]\n",
      "False Positive Rate: 0.365606761437\n",
      "False Negative Rate: 0.325370391639\n",
      "True Positive Rate: 0.280101091984\n",
      "True Negative Rate: 0.902407936891\n",
      "Positive Accuracy: 0.650338446086\n",
      "Negative Accuracy: 0.629380255286\n",
      "Cross Validated Accuracy on Sample: 0.629439905502\n",
      "Cross Validated AUC on Sample: 0.683893141718\n",
      "Train Set Accuracy on Sample: 0.6414\n",
      "\n",
      "Cool\n",
      "[[50529 27541]\n",
      " [ 8573 13357]]\n",
      "False Positive Rate: 0.352773152299\n",
      "False Negative Rate: 0.390925672595\n",
      "True Positive Rate: 0.326592987432\n",
      "True Negative Rate: 0.854945687117\n",
      "Positive Accuracy: 0.582261741906\n",
      "Negative Accuracy: 0.642526010662\n",
      "Cross Validated Accuracy on Sample: 0.624209983625\n",
      "Cross Validated AUC on Sample: 0.651090136574\n",
      "Train Set Accuracy on Sample: 0.63886\n",
      "\n"
     ]
    }
   ],
   "source": [
    "u_tune = 0.00\n",
    "f_tune = 0.00\n",
    "c_tune = 0.00\n",
    "\n",
    "weights = {0:1/(1 - frac_useful + u_tune), 1:1/(frac_useful - u_tune)}\n",
    "log_model = LogReg(C=0.01, penalty='l2', class_weight=weights) #initialize logistic regression model\n",
    "\n",
    "rand = RandomForestClassifier(n_estimators=300, criterion='gini', \n",
    "                              max_features= 17, max_depth=5, class_weight='balanced')\n",
    "\n",
    "\n",
    "\n",
    "useful_words = test_model(x, y_useful, \n",
    "                          log_model,\n",
    "                          \"Useful\",\n",
    "                          coefs=True)\n",
    "funny_words = test_model(x, y_funny, \n",
    "                         log_model.set_params(class_weight={0:1/(1 - frac_funny + f_tune), 1:1/(frac_funny - f_tune)}), \n",
    "                         \"Funny\",\n",
    "                          coefs=True)\n",
    "cool_words = test_model(x, y_cool, \n",
    "                        log_model.set_params(class_weight={0:1/(1 - frac_cool + c_tune), 1:1/(frac_cool - c_tune)}),\n",
    "                        #rand,\n",
    "                        \"Cool\",\n",
    "                          coefs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Coolest Words:\n",
      "like 0.755078060151\n",
      "just 0.650932630418\n",
      "flavors 0.594166484579\n",
      "located 0.557141978293\n",
      "menu 0.517983165153\n",
      "yelp 0.517478710958\n",
      "review 0.501846657456\n",
      "chef 0.498323097554\n",
      "really 0.488916416988\n",
      "ll 0.487814525657\n",
      "\n",
      "10 Least Cool Words:\n",
      "great -0.325067620455\n",
      "bad -0.337038723792\n",
      "terrible -0.348491953549\n",
      "price -0.357142585724\n",
      "manager -0.372340964228\n",
      "worst -0.389642196465\n",
      "horrible -0.398784468502\n",
      "rude -0.498411946847\n",
      "service -0.644688522233\n",
      "food -0.667599936786\n",
      "\n",
      "10 Funniest Words:\n",
      "like 1.15703457555\n",
      "don 0.961634747472\n",
      "just 0.835165187502\n",
      "pretty 0.697534347275\n",
      "know 0.694760996528\n",
      "review 0.60718765986\n",
      "want 0.583590007585\n",
      "wasn 0.551588726153\n",
      "didn 0.500095556799\n",
      "yes 0.499346406054\n",
      "\n",
      "10 Least Funny Words:\n",
      "highly -0.582466540526\n",
      "service -0.615695561086\n",
      "delicious -0.654805720063\n",
      "friendly -0.667676996271\n",
      "amazing -0.684717147884\n",
      "good -0.715257426874\n",
      "excellent -0.719604208411\n",
      "recommend -0.855346632643\n",
      "best -0.886572182226\n",
      "great -1.47971165296\n",
      "\n",
      "10 Most Useful Words:\n",
      "like 0.757365182179\n",
      "just 0.712777685654\n",
      "don 0.642219575671\n",
      "say 0.508115560491\n",
      "way 0.484705628752\n",
      "review 0.479465607085\n",
      "know 0.476188110669\n",
      "think 0.474316906835\n",
      "came 0.465865689572\n",
      "yelp 0.461827959127\n",
      "\n",
      "10 Least Useful Words:\n",
      "friendly -0.353452451361\n",
      "amazing -0.372452523658\n",
      "love -0.479607624977\n",
      "best -0.516914840244\n",
      "excellent -0.531571502467\n",
      "service -0.544098701241\n",
      "awesome -0.576084729978\n",
      "food -0.58947322591\n",
      "good -0.791706705382\n",
      "great -1.09434436986\n"
     ]
    }
   ],
   "source": [
    "print \"10 Coolest Words:\"\n",
    "for word in cool_words[:10]:\n",
    "    print word[1], word[0]\n",
    "\n",
    "print \"\\n10 Least Cool Words:\"\n",
    "for word in cool_words[-10:]:\n",
    "    print word[1], word[0]\n",
    "    \n",
    "print \"\\n10 Funniest Words:\"\n",
    "for word in funny_words[:10]:\n",
    "    print word[1], word[0]\n",
    "\n",
    "print \"\\n10 Least Funny Words:\"\n",
    "for word in funny_words[-10:]:\n",
    "    print word[1], word[0]\n",
    "    \n",
    "print \"\\n10 Most Useful Words:\"\n",
    "for word in useful_words[:10]:\n",
    "    print word[1], word[0]\n",
    "\n",
    "print \"\\n10 Least Useful Words:\"\n",
    "for word in useful_words[-10:]:\n",
    "    print word[1], word[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Useful\n",
      "[[37961 24225]\n",
      " [14053 23761]]\n",
      "False Positive Rate: 0.389557135046\n",
      "False Negative Rate: 0.371634844238\n",
      "True Positive Rate: 0.495165256533\n",
      "True Negative Rate: 0.729822740032\n",
      "Positive Accuracy: 0.620510984993\n",
      "Negative Accuracy: 0.604862843588\n",
      "Cross Validated Accuracy on Sample: 0.606789924084\n",
      "Cross Validated AUC on Sample: 0.648357021728\n",
      "Train Set Accuracy on Sample: 0.61722\n",
      "\n",
      "Funny\n",
      "[[51809 30777]\n",
      " [ 5808 11606]]\n",
      "False Positive Rate: 0.37266606931\n",
      "False Negative Rate: 0.333524750201\n",
      "True Positive Rate: 0.273836207914\n",
      "True Negative Rate: 0.899196417724\n",
      "Positive Accuracy: 0.647524621411\n",
      "Negative Accuracy: 0.628314709203\n",
      "Cross Validated Accuracy on Sample: 0.626159901499\n",
      "Cross Validated AUC on Sample: 0.679360742285\n",
      "Train Set Accuracy on Sample: 0.63415\n",
      "\n",
      "Cool\n",
      "[[50217 27853]\n",
      " [ 8835 13095]]\n",
      "False Positive Rate: 0.356769565774\n",
      "False Negative Rate: 0.402872777018\n",
      "True Positive Rate: 0.319795838625\n",
      "True Negative Rate: 0.850386100386\n",
      "Positive Accuracy: 0.57528499772\n",
      "Negative Accuracy: 0.6432432953\n",
      "Cross Validated Accuracy on Sample: 0.622059980425\n",
      "Cross Validated AUC on Sample: 0.645712321768\n",
      "Train Set Accuracy on Sample: 0.63312\n",
      "\n"
     ]
    }
   ],
   "source": [
    "u_tune = 0.0\n",
    "f_tune = 0.0\n",
    "c_tune = 0.0\n",
    "\n",
    "weights = {0:1/(1 - frac_useful + u_tune), 1:1/(frac_useful - u_tune)}\n",
    "svm = LinearSVC(C=0.001, penalty='l2', class_weight='balanced') #initialize logistic regression model\n",
    "\n",
    "rand = RandomForestClassifier(n_estimators=500, criterion='gini', \n",
    "                              max_features= 17, max_depth=15, class_weight='balanced_subsample')\n",
    "\n",
    "\n",
    "useful_words = test_model(x, y_useful, svm, \"Useful\")\n",
    "funny_words = test_model(x, y_funny, \n",
    "                         svm, \"Funny\")\n",
    "cool_words = test_model(x, y_cool, \n",
    "                        svm, \"Cool\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
